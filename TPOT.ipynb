{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45a23489",
   "metadata": {},
   "source": [
    "# Zindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09a1db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eeef0a2d294e718af68378b6cc8ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "183.21 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: GradientBoostingRegressor(input_matrix, alpha=0.95, learning_rate=0.1, loss=ls, max_depth=10, max_features=0.8, min_samples_leaf=12, min_samples_split=9, n_estimators=100, subsample=0.45)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "train_data = pd.read_csv('train_cleaned_nonBool.csv', low_memory=False)\n",
    "test_data = pd.read_csv('test_cleaned_nonBool.csv', low_memory=False)\n",
    "prophet_preds = pd.read_csv('prophet_prediction.csv', low_memory=False)\n",
    "train_data = train_data.merge(prophet_preds, on='date')\n",
    "test_data = test_data.merge(prophet_preds, on='date')\n",
    "\n",
    "clf = TPOTRegressor(verbosity=2, max_time_mins=90)\n",
    "clf.fit(train_data.drop(columns=['ID','device','date','pm2_5']), train_data['pm2_5'])\n",
    "results = clf.predict(test_data.drop(columns=['ID','device','date']))\n",
    "results= pd.DataFrame(results).rename(columns={0:'pm2_5'})\n",
    "test_data = test_data.join(results)\n",
    "test_data[['ID', 'pm2_5']].to_csv('zindi_tpot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a387520",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data\n",
    "del train_data\n",
    "del clf\n",
    "del results\n",
    "\n",
    "del prophet_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7af562",
   "metadata": {},
   "source": [
    "# Sber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce014336",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "train_data = pd.read_csv('train_sber.csv', low_memory=False)\n",
    "test_data = pd.read_csv('test_sber.csv', low_memory=False)\n",
    "\n",
    "clf = TPOTRegressor(verbosity=2, max_time_mins=5)\n",
    "clf.fit(train_data.drop(columns=['id', 'timestamp', 'price_doc', 'product_type', 'sub_area']), train_data['price_doc'])\n",
    "results = clf.predict(test_data.drop(columns=['id', 'timestamp', 'product_type', 'sub_area']))\n",
    "results= pd.DataFrame(results).rename(columns={0:'price_doc'})\n",
    "test_data = test_data.join(preds)\n",
    "test_data[['id', 'price_doc']].to_csv('sber_tpot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9887a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051eb575",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data\n",
    "del train_data\n",
    "del clf\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfad0f5",
   "metadata": {},
   "source": [
    "# Santander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bbf41e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95101693dfc94ce598ed4b284366040b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "93.01 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: GradientBoostingClassifier(input_matrix, learning_rate=0.01, max_depth=4, max_features=0.8, min_samples_leaf=10, min_samples_split=12, n_estimators=100, subsample=0.3)\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "train_data = pd.read_csv('train_santander.csv', low_memory=False)\n",
    "test_data = pd.read_csv('test_santander.csv', low_memory=False)\n",
    "\n",
    "clf = TPOTClassifier(verbosity=2, max_time_mins=90)\n",
    "clf.fit(train_data.drop(columns=['ID','TARGET']), train_data['TARGET'])\n",
    "results = clf.predict(test_data.drop(columns=['ID']))\n",
    "preds = pd.DataFrame(results).rename(columns={0:'TARGET'})\n",
    "test_data = test_data.join(preds)\n",
    "test_data[['ID', 'TARGET']].to_csv('santander_tpot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102ed0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data\n",
    "del train_data\n",
    "del clf\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fa2dfd",
   "metadata": {},
   "source": [
    "# Liberty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624909de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'A'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m test_data \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m     15\u001b[0m clf \u001b[38;5;241m=\u001b[39m TPOTRegressor(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_time_mins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]), train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m results \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(test_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     18\u001b[0m preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:726\u001b[0m, in \u001b[0;36mTPOTBase.fit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m\"\"\"Fit an optimized machine learning pipeline.\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03mUses genetic programming to optimize a machine learning pipeline that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    723\u001b[0m \n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_init()\n\u001b[1;32m--> 726\u001b[0m features, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pretest(features, target)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;66;03m# Randomly collect a subsample of training samples for pipeline optimization process.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:1376\u001b[0m, in \u001b[0;36mTPOTBase._check_dataset\u001b[1;34m(self, features, target, sample_weight)\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imputed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imputed:\n\u001b[1;32m-> 1376\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:1317\u001b[0m, in \u001b[0;36mTPOTBase._impute_values\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_imputer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fitted_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_imputer\u001b[38;5;241m.\u001b[39mtransform(features)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\impute\\_base.py:364\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    356\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter was deprecated in version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    362\u001b[0m     )\n\u001b[1;32m--> 364\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\impute\\_base.py:317\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    312\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    315\u001b[0m         )\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'A'"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "train_data = pd.read_csv('train_liberty.csv', low_memory=False)\n",
    "train_data = train_data.replace('Z', np.nan)\n",
    "test_data = pd.read_csv('test_liberty.csv', low_memory=False)\n",
    "test_data = test_data.replace('Z', np.nan)\n",
    "\n",
    "clf = TPOTRegressor(verbosity=2, max_time_mins=5)\n",
    "clf.fit(train_data.drop(columns=['id','target']), train_data['target'])\n",
    "results = clf.predict(test_data.drop(columns=['id']))\n",
    "preds = pd.DataFrame(results).rename(columns={0:'target'})\n",
    "test_data = test_data.join(preds)\n",
    "test_data[['id', 'target']].to_csv('liberty_tpot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61dda2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data\n",
    "del train_data\n",
    "del clf\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b03fd",
   "metadata": {},
   "source": [
    "# Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8a37a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88eb777b229b4c7bbcb3aad9613675fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/100 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7.08 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m test_data \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNA\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m     15\u001b[0m clf \u001b[38;5;241m=\u001b[39m TPOTRegressor(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_time_mins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]), train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m results \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(test_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     18\u001b[0m preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:863\u001b[0m, in \u001b[0;36mTPOTBase.fit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    861\u001b[0m         \u001b[38;5;66;03m# raise the exception if it's our last attempt\u001b[39;00m\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m attempt \u001b[38;5;241m==\u001b[39m (attempts \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 863\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:854\u001b[0m, in \u001b[0;36mTPOTBase.fit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pbar, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pbar\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 854\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_top_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_of_best_pipeline(features, target)\n\u001b[0;32m    856\u001b[0m \u001b[38;5;66;03m# Delete the temporary cache before exiting\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:934\u001b[0m, in \u001b[0;36mTPOTBase._update_top_pipeline\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    924\u001b[0m             cv_scores \u001b[38;5;241m=\u001b[39m cross_val_score(\n\u001b[0;32m    925\u001b[0m                 sklearn_pipeline,\n\u001b[0;32m    926\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretest_X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    931\u001b[0m                 error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    932\u001b[0m             )\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    935\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was an error in the TPOT optimization \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocess. This could be because the data was \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot formatted properly, or because data for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma regression problem was provided to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTPOTClassifier object. Please make sure you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed the data to TPOT correctly. If you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menabled PyTorch estimators, please check \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe data requirements in the online \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocumentation: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://epistasislab.github.io/tpot/using/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    945\u001b[0m     )\n\u001b[0;32m    946\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    947\u001b[0m     pareto_front_wvalues \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    948\u001b[0m         pipeline_scores\u001b[38;5;241m.\u001b[39mwvalues[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    949\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m pipeline_scores \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pareto_front\u001b[38;5;241m.\u001b[39mkeys\n\u001b[0;32m    950\u001b[0m     ]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: There was an error in the TPOT optimization process. This could be because the data was not formatted properly, or because data for a regression problem was provided to the TPOTClassifier object. Please make sure you passed the data to TPOT correctly. If you enabled PyTorch estimators, please check the data requirements in the online documentation: https://epistasislab.github.io/tpot/using/"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "train_data = pd.read_csv('train_loan.csv', low_memory=False)\n",
    "train_data = train_data.replace('NA', np.nan)\n",
    "test_data = pd.read_csv('test_loan.csv', low_memory=False)\n",
    "test_data = test_data.replace('NA', np.nan)\n",
    "\n",
    "clf = TPOTRegressor(verbosity=2, max_time_mins=5)\n",
    "clf.fit(train_data.drop(columns=['id','loss']), train_data['loss'])\n",
    "results = clf.predict(test_data.drop(columns=['id']))\n",
    "preds = pd.DataFrame(results).rename(columns={0:'loss'})\n",
    "test_data = test_data.join(preds)\n",
    "test_data[['id', 'loss']].to_csv('loan_tpot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4468ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_data\n",
    "del train_data\n",
    "del clf\n",
    "del results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7cf09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputing missing values in feature set\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'Hombre'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, low_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m clf \u001b[38;5;241m=\u001b[39m TPOTRegressor(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, max_time_mins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValor dólar informal semestral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentificador\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAño\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSemestre\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]), train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     18\u001b[0m results \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(test_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValor dólar informal semestral\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentificador\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAño\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSemestre\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     19\u001b[0m results\u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results)\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m0\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m})\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:726\u001b[0m, in \u001b[0;36mTPOTBase.fit\u001b[1;34m(self, features, target, sample_weight, groups)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;124;03m\"\"\"Fit an optimized machine learning pipeline.\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03mUses genetic programming to optimize a machine learning pipeline that\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    723\u001b[0m \n\u001b[0;32m    724\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_init()\n\u001b[1;32m--> 726\u001b[0m features, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pretest(features, target)\n\u001b[0;32m    730\u001b[0m \u001b[38;5;66;03m# Randomly collect a subsample of training samples for pipeline optimization process.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:1376\u001b[0m, in \u001b[0;36mTPOTBase._check_dataset\u001b[1;34m(self, features, target, sample_weight)\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imputed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imputed:\n\u001b[1;32m-> 1376\u001b[0m         features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Anaconda\\envs\\tpot\\lib\\site-packages\\tpot\\base.py:1317\u001b[0m, in \u001b[0;36mTPOTBase._impute_values\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_imputer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1317\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fitted_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fitted_imputer\u001b[38;5;241m.\u001b[39mtransform(features)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\impute\\_base.py:364\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    356\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter was deprecated in version \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.1 and will be removed in 1.3. A warning will \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    362\u001b[0m     )\n\u001b[1;32m--> 364\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\impute\\_base.py:317\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[1;34m(self, X, in_fit)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[0;32m    312\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    314\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[0;32m    315\u001b[0m         )\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'Hombre'"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "col_to_drop = ['Valor dólar informal semestral', 'identificador', 'Año', 'Semestre', 'target']\n",
    "\n",
    "train_data = pd.read_csv('train_data.csv', low_memory=False)\n",
    "train_data['target'] = train_data['Valor dólar informal semestral']*train_data['Salario mensual (en tu moneda local)']\n",
    "test_data = pd.read_csv('features.csv', low_memory=False)\n",
    "\n",
    "clf = TPOTRegressor(verbosity=2, max_time_mins=10)\n",
    "clf.fit(train_data.drop(columns=['Valor dólar informal semestral', 'identificador', 'Año', 'Semestre', 'target']), train_data['target'])\n",
    "results = clf.predict(test_data.drop(columns=['Valor dólar informal semestral', 'identificador', 'Año', 'Semestre']))\n",
    "results= pd.DataFrame(results).rename(columns={0:'target'})\n",
    "test_data = test_data.join(results)\n",
    "test_data[['identificador', 'target']].to_csv('rga_tpot.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34368a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TPOT AutoML",
   "language": "python",
   "name": "tpot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
